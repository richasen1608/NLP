# -*- coding: utf-8 -*-
"""Tokenization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FLW5Ul76QRMa5irAxzzw6QNy2E4noPuI
"""

!pip install nltk

corpus="""hello welcome, how are you?
I hope you are doing well!
"""

corpus

print(corpus)

#tokenization

from nltk.tokenize import sent_tokenize

import nltk

nltk.download('punkt')
sent_tokenize(corpus)

documents=sent_tokenize(corpus)

type(documents)

for sentence in documents:
  print(sentence)

#tokenization
#paragraph into words
#sentence into words

from nltk.tokenize import word_tokenize

word_tokenize(corpus)

for sentence in documents:
  print(word_tokenize (sentence))

from nltk.tokenize import wordpunct_tokenize

wordpunct_tokenize(corpus)

from nltk.tokenize import TreebankWordDetokenizer

treebank=TreebankWordDetokenizer()

treebank.tokenize(corpus)



